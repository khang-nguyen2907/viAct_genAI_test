{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWGvsaXWuF6l"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4UJTzNft312",
        "outputId": "f5bab68c-d94b-418d-dccb-ee4112b7aab5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-0.4.20-py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.7/507.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain\n",
            "  Downloading langchain-0.0.351-py3-none-any.whl (794 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m794.3/794.3 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypdf2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting streamlit\n",
            "  Downloading streamlit-1.29.0-py2.py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.31.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.10.13)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.105.0-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
            "  Downloading uvicorn-0.24.0.post1-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.23.5)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.1.0-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.5.0)\n",
            "Collecting pulsar-client>=3.1.0 (from chromadb)\n",
            "  Downloading pulsar_client-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.22.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.22.0-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.42b0-py3-none-any.whl (11 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.22.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.6/105.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.15.0)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.4.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.1.1)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.60.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl (698 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.9.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-28.1.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (8.2.3)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.1)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-4.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.6/72.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.2 (from langchain)\n",
            "  Downloading langchain_community-0.0.4-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1 (from langchain)\n",
            "  Downloading langchain_core-0.1.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1.0,>=0.0.70 (from langchain)\n",
            "  Downloading langsmith-0.0.72-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Collecting importlib-metadata<7,>=1.4 (from streamlit)\n",
            "  Downloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.2)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.5.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=6.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (10.0.1)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.8.2)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.2)\n",
            "Collecting validators<1,>=0.2 (from streamlit)\n",
            "  Downloading validators-0.22.0-py3-none-any.whl (26 kB)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.2)\n",
            "Collecting watchdog>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (3.7.1)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions>=4.5.0 (from chromadb)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7,>=1.4->streamlit) (3.17.0)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2023.11.17)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.17.3)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Collecting urllib3<2.0,>=1.24.2 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting backoff<3.0.0,>=1.10.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.62.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.22.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.22.0-py3-none-any.whl (17 kB)\n",
            "Collecting opentelemetry-proto==1.22.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.22.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-instrumentation-asgi==0.42b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.42b0-py3-none-any.whl (13 kB)\n",
            "Collecting opentelemetry-instrumentation==0.42b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.42b0-py3-none-any.whl (25 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.42b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.42b0-py3-none-any.whl (36 kB)\n",
            "Collecting opentelemetry-util-http==0.42b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.42b0-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.42b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (67.7.2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.42b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.42b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.7.2-py3-none-any.whl (24 kB)\n",
            "INFO: pip is looking at multiple versions of opentelemetry-sdk to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.41b0-py3-none-any.whl (11 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.41b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.41b0-py3-none-any.whl (13 kB)\n",
            "Collecting opentelemetry-instrumentation==0.41b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.41b0-py3-none-any.whl (25 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.41b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.41b0-py3-none-any.whl (26 kB)\n",
            "Collecting opentelemetry-util-http==0.41b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.41b0-py3-none-any.whl (6.9 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.21.0-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.21.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.3/105.3 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.21.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-common==1.21.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.21.0-py3-none-any.whl (17 kB)\n",
            "Collecting opentelemetry-proto==1.21.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.21.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.3.post1)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.6)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.2)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.19.4)\n",
            "Collecting h11>=0.8 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi>=0.95.2->chromadb) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi>=0.95.2->chromadb) (1.2.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.32.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.13.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.5.1)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=d617236baf5a989289ebd2c71e2e570255fc3b4cdeb064ee85db075be9a50052\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, mmh3, websockets, watchdog, validators, uvloop, urllib3, typing-extensions, smmap, python-dotenv, pypdf2, pulsar-client, overrides, opentelemetry-util-http, opentelemetry-semantic-conventions, opentelemetry-proto, mypy-extensions, marshmallow, jsonpointer, importlib-metadata, humanfriendly, httptools, h11, deprecated, chroma-hnswlib, bcrypt, backoff, watchfiles, uvicorn, typing-inspect, starlette, pydeck, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, jsonpatch, gitdb, coloredlogs, asgiref, tiktoken, posthog, opentelemetry-sdk, opentelemetry-instrumentation, onnxruntime, langsmith, gitpython, fastapi, dataclasses-json, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, langchain-core, kubernetes, streamlit, opentelemetry-instrumentation-fastapi, langchain-community, langchain, chromadb\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 7.0.0\n",
            "    Uninstalling importlib-metadata-7.0.0:\n",
            "      Successfully uninstalled importlib-metadata-7.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed asgiref-3.7.2 backoff-2.2.1 bcrypt-4.1.2 chroma-hnswlib-0.7.3 chromadb-0.4.20 coloredlogs-15.0.1 dataclasses-json-0.6.3 deprecated-1.2.14 fastapi-0.105.0 gitdb-4.0.11 gitpython-3.1.40 h11-0.14.0 httptools-0.6.1 humanfriendly-10.0 importlib-metadata-6.11.0 jsonpatch-1.33 jsonpointer-2.4 kubernetes-28.1.0 langchain-0.0.351 langchain-community-0.0.4 langchain-core-0.1.1 langsmith-0.0.72 marshmallow-3.20.1 mmh3-4.0.1 monotonic-1.6 mypy-extensions-1.0.0 onnxruntime-1.16.3 opentelemetry-api-1.21.0 opentelemetry-exporter-otlp-proto-common-1.21.0 opentelemetry-exporter-otlp-proto-grpc-1.21.0 opentelemetry-instrumentation-0.42b0 opentelemetry-instrumentation-asgi-0.42b0 opentelemetry-instrumentation-fastapi-0.42b0 opentelemetry-proto-1.21.0 opentelemetry-sdk-1.21.0 opentelemetry-semantic-conventions-0.42b0 opentelemetry-util-http-0.42b0 overrides-7.4.0 posthog-3.1.0 pulsar-client-3.3.0 pydeck-0.8.1b0 pypdf2-3.0.1 pypika-0.48.9 python-dotenv-1.0.0 smmap-5.0.1 starlette-0.27.0 streamlit-1.29.0 tiktoken-0.5.2 typing-extensions-4.9.0 typing-inspect-0.9.0 urllib3-1.26.18 uvicorn-0.24.0.post1 uvloop-0.19.0 validators-0.22.0 watchdog-3.0.0 watchfiles-0.21.0 websockets-12.0\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-3.17.3-py3-none-any.whl (277 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.9/277.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-3.17.3\n",
            "Collecting openai\n",
            "  Downloading openai-1.5.0-py3-none-any.whl (223 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.7/223.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Installing collected packages: httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed httpcore-1.0.2 httpx-0.25.2 openai-1.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install chromadb langchain pypdf2 tiktoken streamlit python-dotenv\n",
        "!pip install pypdf\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2-SLLEgfeVP"
      },
      "source": [
        "There is a .pdf example for quick test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcKg21l99uCJ",
        "outputId": "1caa596c-cc16-4e2b-9398-1c48056e4ca4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1jsF4rg70BZT9CJy-l4LXstyQThW_qXrz\n",
            "To: /content/Laws of the Game 2023_24.pdf\n",
            "100% 66.1M/66.1M [00:01<00:00, 47.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1jsF4rg70BZT9CJy-l4LXstyQThW_qXrz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m74tqpN3uHcH"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_DnEvghZuFk-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "from langchain.document_loaders import PyPDFLoader, TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.vectorstores import Chroma\n",
        "import chromadb\n",
        "# Set logging for the queries\n",
        "import logging\n",
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "\n",
        "logging.basicConfig()\n",
        "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)\n",
        "\n",
        "# RetrievalQA\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx8_BQbzuJr-"
      },
      "source": [
        "# Document Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GoTMj98xuLYS"
      },
      "outputs": [],
      "source": [
        "def load_documents(file_path):\n",
        "    documents = None\n",
        "    if file_path.endswith(\".pdf\"):\n",
        "        loader = PyPDFLoader(file_path)\n",
        "        documents = loader.load()\n",
        "    elif file_path.endswith(\".txt\"):\n",
        "        loader = TextLoader(file_path)\n",
        "        documents = loader.load()\n",
        "    else:\n",
        "        raise ValueError(f\"`file_path` expected `.pdf` or `.txt`, but got .{os.path.splitext(file_path)[-1]}\")\n",
        "    return documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCIMeww2uNZv"
      },
      "source": [
        "# Vector Database initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VXLNvm8fuQ8X"
      },
      "outputs": [],
      "source": [
        "def load_chunk_persist_pdf(\n",
        "        path,\n",
        "        chunk_size: int = 1000,\n",
        "        chunk_overlap: int = 10,\n",
        "        saved_persist_directory: str = \"./chroma_store\",\n",
        ") -> Chroma:\n",
        "    \"\"\"\n",
        "    Load files and create vector database\n",
        "    Args:\n",
        "        path:\n",
        "            path to `.pdf` or `.txt` file or path to directory\n",
        "            containing `.pdf` or `.txt` files\n",
        "        chunk_size:\n",
        "            Length of a chunk after being splitted from a document\n",
        "        chunk_overlap:\n",
        "            Number of overlapped character between current and previous chunk\n",
        "        saved_persist_directory:\n",
        "            path to the directory which saves vector database\n",
        "\n",
        "    Returns:\n",
        "        Chroma vector database\n",
        "    TODO:\n",
        "        - Test if document A and document B are unexpectedly combined by chunk_overlap\n",
        "        - verify the metric of this vector database\n",
        "    \"\"\"\n",
        "    documents = []\n",
        "    if os.path.isdir(path):\n",
        "        for f in os.listdir(path):\n",
        "            documents_ = load_documents(\n",
        "                os.path.join(path, f)\n",
        "            )\n",
        "            documents.extend(documents_)\n",
        "    else:\n",
        "        documents.extend(load_documents(path))\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap\n",
        "    )\n",
        "    chunked_documents = text_splitter.split_documents(documents)\n",
        "    client = chromadb.Client()\n",
        "    if client.list_collections():\n",
        "        consent_collection = client.create_collection(\"consent_collection\")\n",
        "    else:\n",
        "        print(\"Collection already exists\")\n",
        "    vectordb = Chroma.from_documents(\n",
        "        documents=chunked_documents,\n",
        "        embedding=OpenAIEmbeddings(),\n",
        "        persist_directory=saved_persist_directory\n",
        "    )\n",
        "    vectordb.persist()\n",
        "    return vectordb\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BN8ZGUj1uZuO"
      },
      "source": [
        "# Init LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FSiZuk-QuasV"
      },
      "outputs": [],
      "source": [
        "def init_llm(\n",
        "        model_name: str,\n",
        "        temperature: float = 0.7\n",
        "):\n",
        "    llm = ChatOpenAI(\n",
        "        # openai_api_key=OPENAI_API_KEY,\n",
        "        model_name=model_name,\n",
        "        temperature=temperature\n",
        "    )\n",
        "    return llm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sooApWEJulO2"
      },
      "source": [
        "# Init RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YScmQPFGukYF"
      },
      "outputs": [],
      "source": [
        "def init_naive_rag(\n",
        "        llm,\n",
        "        retriever,\n",
        "):\n",
        "    rag = RetrievalQA.from_chain_type(\n",
        "        llm,\n",
        "        retriever=retriever,\n",
        "        return_source_documents=True\n",
        "        #chain_type_kwargs={\"prompt\": prompt}\n",
        "    )\n",
        "\n",
        "    return rag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ZE5a6t4bRxOs"
      },
      "outputs": [],
      "source": [
        "def rag_pipeline_wo_decompose(qa_chain, query):\n",
        "    result = qa_chain({\"query\": query})\n",
        "    answer = result[\"result\"]\n",
        "    sources = dict()\n",
        "    print(\"Full source: \", result[\"source_documents\"])\n",
        "    for d in result[\"source_documents\"]:\n",
        "        if d.metadata[\"source\"] not in sources:\n",
        "            sources[d.metadata[\"source\"]] = {str(d.metadata[\"page\"])}\n",
        "        else:\n",
        "            sources[d.metadata[\"source\"]].add(str(d.metadata[\"page\"]))\n",
        "    return answer, sources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "bec48tlnMxa3"
      },
      "outputs": [],
      "source": [
        "def inference_wo_decompose(\n",
        "        model_name=\"gpt-3.5-turbo\",\n",
        "        temperature=0.7):\n",
        "    file_path = str(input(\"Please provide path to `.pdf` or `.txt` file or directory consists of multiple files: \\n\"))\n",
        "    print(f\"Processing documents from {file_path}\")\n",
        "    vectordb = load_chunk_persist_pdf(\n",
        "        path=file_path\n",
        "    )\n",
        "    print(\"Vector database is initialized.\")\n",
        "    print(\"LLM: \", model_name)\n",
        "    llm = init_llm(model_name=model_name, temperature=temperature)\n",
        "    rag = init_naive_rag(\n",
        "        llm=llm,\n",
        "        retriever=vectordb.as_retriever(),\n",
        "    )\n",
        "\n",
        "    print(\">>Bot: Welcome! Please ask me anything about the documents\")\n",
        "    print(\"Type `:q` to end the chat\")\n",
        "    while True:\n",
        "        user_input = str(input(\">>User:\"))\n",
        "        if user_input.lower().startswith(\":q\"):\n",
        "            print(\">>Bot: Bye!\")\n",
        "            break\n",
        "        answer, sources = rag_pipeline_wo_decompose(rag, user_input)\n",
        "        print(\">>Bot: \", answer)\n",
        "        sources_ = \"\\n\".join([f\"Source: {s} | Page: {p}\" for s, p in sources.items()])\n",
        "        print(f\">>Bot: {sources_}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1n2BM_R-HsW",
        "outputId": "10ce849e-5ec2-4b2d-9e2e-2dc3b87939eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please provide path to `.pdf` or `.txt` file or directory consists of multiple files: \n",
            "/content/Laws of the Game 2023_24.pdf\n",
            "Processing documents from /content/Laws of the Game 2023_24.pdf\n",
            "Collection already exists\n",
            "Vector database is initialized.\n",
            "LLM:  gpt-3.5-turbo\n",
            ">>Bot: Welcome! Please ask me anything about the documents\n",
            "Type `:q` to end the chat\n",
            ">>User:Is a Handball a ‘Direct’ or ‘Indirect’ Kick?\n",
            "Full source:  [Document(page_content='touched another player, an indirect free kick is awarded; if the kicker commits \\na handball offence:\\n•\\u2002a direct free kick is awarded\\n•\\u2002 a penalty kick is awarded if the offence occurred inside the kicker’s penalty \\narea, unless the kicker was the goalkeeper, in which case an indirect free kick \\nis awardedThe Corner Kick', metadata={'page': 132, 'source': '/content/Laws of the Game 2023_24.pdf'}), Document(page_content='touched another player, an indirect free kick is awarded; if the kicker commits \\na handball offence:\\n•\\u2002a direct free kick is awarded\\n•\\u2002 a penalty kick is awarded if the offence occurred inside the kicker’s penalty \\narea, unless the kicker was the goalkeeper, in which case an indirect free kick \\nis awardedThe Corner Kick', metadata={'page': 132, 'source': '/content/Laws of the Game 2023_24.pdf'}), Document(page_content='touched another player, an indirect free kick is awarded; if the kicker commits \\na handball offence:\\n•\\u2002a direct free kick is awarded\\n•\\u2002 a penalty kick is awarded if the offence occurred inside the kicker’s penalty \\narea, unless the kicker was the goalkeeper, in which case an indirect free kick \\nis awardedThe Corner Kick', metadata={'page': 132, 'source': '/content/Laws of the Game 2023_24.pdf'}), Document(page_content='touched another player, an indirect free kick is awarded; if the kicker commits \\na handball offence:\\n•\\u2002a direct free kick is awarded\\n•\\u2002 a penalty kick is awarded if the offence occurred inside the kicker’s penalty \\narea, unless the kicker was the goalkeeper, in which case an indirect free kick \\nis awardedThe Corner Kick', metadata={'page': 132, 'source': '/content/Laws of the Game 2023_24.pdf'})]\n",
            ">>Bot:  A handball offense in soccer results in a direct free kick being awarded.\n",
            ">>Bot: Source: /content/Laws of the Game 2023_24.pdf | Page: {'132'}\n",
            ">>User:What impact do external factors such as weather conditions have on the outcome of football matches?\n",
            "Full source:  [Document(page_content='should also pay attention to:\\n\\u2002•player confrontations off the ball\\n\\u2002•possible offences in the area towards which play is moving\\n\\u2002•offences occurring after the ball is played awayPositioning, movement \\nand teamwork', metadata={'page': 177, 'source': '/content/Laws of the Game 2023_24.pdf'}), Document(page_content='should also pay attention to:\\n\\u2002•player confrontations off the ball\\n\\u2002•possible offences in the area towards which play is moving\\n\\u2002•offences occurring after the ball is played awayPositioning, movement \\nand teamwork', metadata={'page': 177, 'source': '/content/Laws of the Game 2023_24.pdf'}), Document(page_content='should also pay attention to:\\n\\u2002•player confrontations off the ball\\n\\u2002•possible offences in the area towards which play is moving\\n\\u2002•offences occurring after the ball is played awayPositioning, movement \\nand teamwork', metadata={'page': 177, 'source': '/content/Laws of the Game 2023_24.pdf'}), Document(page_content='should also pay attention to:\\n\\u2002•player confrontations off the ball\\n\\u2002•possible offences in the area towards which play is moving\\n\\u2002•offences occurring after the ball is played awayPositioning, movement \\nand teamwork', metadata={'page': 177, 'source': '/content/Laws of the Game 2023_24.pdf'})]\n",
            ">>Bot:  External factors such as weather conditions can have a significant impact on the outcome of football matches. For example, heavy rain or strong winds can affect the trajectory of the ball, making it more difficult for players to control and pass accurately. This can lead to more turnovers and unpredictable bounces, which can ultimately influence the outcome of the game. Additionally, extreme heat or cold weather can also affect the players' physical performance and stamina, potentially affecting their ability to execute their skills effectively. Therefore, it is important for teams to adapt their strategies and tactics accordingly based on the weather conditions to maximize their chances of success.\n",
            ">>Bot: Source: /content/Laws of the Game 2023_24.pdf | Page: {'177'}\n",
            ">>User::q\n",
            ">>Bot: Bye!\n"
          ]
        }
      ],
      "source": [
        "inference_wo_decompose()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t7Odal8u-68"
      },
      "source": [
        "# Decomposition (Addition)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "kiF81XbJvAeI"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "DECOMPOSE_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"\"\"You are an AI assistant that specializes in breaking down complex questions into five different simpler, manageable sub-questions.\n",
        "    When presented with a complex user question, your role is to generate a list of sub-questions that, when answered, will comprehensively address the original query.\n",
        "    You have at your disposal a pre-defined set of functions and data sources to utilize in answering each sub-question.\n",
        "    If a user question is straightforward, your task is to return the original question, identifying the appropriate function and data source to use for its solution.\n",
        "    Please remember that you are limited to the provided functions and data sources, and that each sub-question should be a full question that can be answered using a single function and a single data source.\n",
        "    Provide these alternative questions separated by newlines.\n",
        "    Original question: {question}\"\"\"\n",
        ")\n",
        "\n",
        "def get_multi_query_retriever(llm, retriever, prompt=None):\n",
        "    if not prompt:\n",
        "        prompt = DECOMPOSE_PROMPT\n",
        "    m_retriever = MultiQueryRetriever.from_llm(\n",
        "        retriever=retriever, llm=llm, prompt=prompt\n",
        "    )\n",
        "    return m_retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "OthrxC5LvDjz"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "QA_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"query\", \"contexts\"],\n",
        "    template=\"\"\"You are a helpful assistant who answers user queries using the\n",
        "    contexts provided. If the question cannot be answered using the information\n",
        "    provided say \"I don't know\".\n",
        "\n",
        "    Contexts:\n",
        "    {contexts}\n",
        "\n",
        "    Question: {query}\"\"\"\n",
        ")\n",
        "\n",
        "def get_qa_chain(llm, prompt=None):\n",
        "    if not prompt:\n",
        "        prompt = QA_PROMPT\n",
        "    rag_chain = LLMChain(llm=llm, prompt=prompt)\n",
        "    return rag_chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "Z9qzGEXOQk90"
      },
      "outputs": [],
      "source": [
        "def rag_pipeline_w_decompose(query_chain, qa_chain, query):\n",
        "    docs = query_chain.get_relevant_documents(query=query)\n",
        "    result = qa_chain(\n",
        "        inputs={\n",
        "            \"query\": query,\n",
        "            \"contexts\": \"\\n===\\n\".join([d.page_content for d in docs])\n",
        "        }\n",
        "    )\n",
        "    answer = result[\"text\"]\n",
        "    sources = dict()\n",
        "    print(\"Full source: \", docs)\n",
        "    for d in docs:\n",
        "        if d.metadata[\"source\"] not in sources:\n",
        "            sources[d.metadata[\"source\"]] = {str(d.metadata[\"page\"])}\n",
        "        else:\n",
        "            sources[d.metadata[\"source\"]].add(str(d.metadata[\"page\"]))\n",
        "\n",
        "    return answer, sources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "6yv-ZggHPNSC"
      },
      "outputs": [],
      "source": [
        "def inference_w_decompose(\n",
        "        model_name=\"gpt-3.5-turbo\",\n",
        "        temperature=0.7):\n",
        "    file_path = str(input(\"Please provide path to `.pdf` or `.txt` file or directory consists of multiple files: \\n\"))\n",
        "    print(f\"Processing documents from {file_path}\")\n",
        "    vectordb = load_chunk_persist_pdf(\n",
        "        path=file_path\n",
        "    )\n",
        "    print(\"Vector database is initialized.\")\n",
        "    print(\"LLM: \", model_name)\n",
        "    llm = init_llm(model_name=model_name, temperature=temperature)\n",
        "\n",
        "    multiquery = get_multi_query_retriever(llm, vectordb.as_retriever(), prompt=DECOMPOSE_PROMPT)\n",
        "    qa_chain = get_qa_chain(llm, prompt=QA_PROMPT)\n",
        "\n",
        "    print(\">>Bot: Welcome! Please ask me anything about the documents\")\n",
        "    print(\"Type `:q` to end the chat\")\n",
        "    while True:\n",
        "        user_input = str(input(\">>User:\"))\n",
        "        if user_input.lower().startswith(\":q\"):\n",
        "            print(\">>Bot: Bye!\")\n",
        "            break\n",
        "        answer, sources = rag_pipeline_w_decompose(multiquery, qa_chain, user_input)\n",
        "        print(\">>Bot: \", answer)\n",
        "        sources_ = \"\\n\".join([f\"Source: {s} | Page: {p}\" for s, p in sources.items()])\n",
        "        print(f\">>Bot: {sources_}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENSzmnubTqdM",
        "outputId": "8f12a320-d6b5-48ad-a71f-25c3ccd2801c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please provide path to `.pdf` or `.txt` file or directory consists of multiple files: \n",
            "/content/Laws of the Game 2023_24.pdf\n",
            "Processing documents from /content/Laws of the Game 2023_24.pdf\n",
            "Collection already exists\n",
            "Vector database is initialized.\n",
            "LLM:  gpt-3.5-turbo\n",
            ">>Bot: Welcome! Please ask me anything about the documents\n",
            "Type `:q` to end the chat\n",
            ">>User:Is a Handball a ‘Direct’ or ‘Indirect’ Kick?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:langchain.retrievers.multi_query:Generated queries: ['1. What is the definition of a Handball in the context of sports?', '2. What are the different types of kicks in handball?', \"3. How is a 'Direct' kick defined in handball?\", \"4. How is an 'Indirect' kick defined in handball?\", \"5. Is a handball considered a 'Direct' or 'Indirect' kick in handball?\"]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Full source:  [Document(page_content='hand/arm being hit by the ball and being penalised\\n•\\u2002scores in the opponents’ goal: \\n\\u2002• directly from their hand/arm, even if accidental, including by the \\ngoalkeeper\\n\\u2002• immediately after the ball has touched their hand/arm, even if accidental\\n The goalkeeper has the same restrictions on handling the ball as any other \\nplayer outside the penalty area.  If the goalkeeper handles the ball inside their \\npenalty area when not permitted to do so, an indirect free kick is awarded but \\nthere is no disciplinary sanction. However, if the offence is playing the ball a \\nsecond time (with or without the hand/arm) after a restart before it touches \\nanother player, the goalkeeper must be sanctioned if the offence stops a \\npromising attack or denies an opponent or the opposing team a goal or an \\nobvious goal-scoring opportunity.11No handball\\nHandball\\n1111No handball\\nHandballHandball', metadata={'page': 99, 'source': '/content/Laws of the Game 2023_24.pdf'}), Document(page_content='touched another player, an indirect free kick is awarded; if the kicker commits \\na handball offence:\\n•\\u2002a direct free kick is awarded\\n•\\u2002 a penalty kick is awarded if the offence occurred inside the kicker’s penalty \\narea, unless the kicker was the goalkeeper, in which case an indirect free kick \\nis awardedThe Corner Kick', metadata={'page': 132, 'source': '/content/Laws of the Game 2023_24.pdf'})]\n",
            ">>Bot:  A handball can result in either a direct free kick or an indirect free kick, depending on the specific circumstances. If a player commits a handball offence, a direct free kick is awarded. However, if the handball offence occurs inside the kicker's penalty area and the kicker is not the goalkeeper, a penalty kick is awarded. If the kicker is the goalkeeper, an indirect free kick is awarded.\n",
            ">>Bot: Source: /content/Laws of the Game 2023_24.pdf | Page: {'132', '99'}\n",
            ">>User:What impact do external factors such as weather conditions have on the outcome of football matches?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:langchain.retrievers.multi_query:Generated queries: ['1. How do weather conditions affect the outcome of football matches?', '2. What are the specific external factors, other than weather conditions, that can influence the outcome of football matches?', '3. Can we quantify the impact of weather conditions on the outcome of football matches?', '4. Are there any historical data or studies that analyze the relationship between weather conditions and the outcome of football matches?', '5. Are there any strategies or tactics that teams can use to mitigate the impact of external factors on the outcome of football matches?']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Full source:  [Document(page_content='particular match  (see Law 5)\\nSuspend  \\nTo stop a match for a period of time with the intention of eventually restarting \\nplay e.g. due to fog, heavy rain, thunderstorm, serious injury\\nT\\nTackle  \\nA challenge for the ball with the foot (on the ground or in the air)\\nTeam list  \\nOfficial team document usually listing the players, substitutes and team officials', metadata={'page': 171, 'source': '/content/Laws of the Game 2023_24.pdf'}), Document(page_content='should also pay attention to:\\n\\u2002•player confrontations off the ball\\n\\u2002•possible offences in the area towards which play is moving\\n\\u2002•offences occurring after the ball is played awayPositioning, movement \\nand teamwork', metadata={'page': 177, 'source': '/content/Laws of the Game 2023_24.pdf'}), Document(page_content='156Law 7 – The Duration of the Match (p. 77)\\n3. Allowance for time lost\\nAmended text\\nAllowance is made by the referee in each half for all playing time lost in that half \\nthrough: \\n\\u2002•substitutions\\n\\u2002•(…)\\n\\u2002•goal celebrations\\n\\u2002• any other cause, including any significant delay to a restart (e.g. goal \\ncelebrations due to interference by an outside agent )\\nExplanation\\nGoal celebrations will henceforth be listed separately to emphasise that they \\noften result in a significant amount of time being lost, for which the referee \\nmakes allowance.\\nLaw 10 – Determining the Outcome of a Match (p. 87)\\n2. Winning team\\nAmended text\\n(…)\\nWhen competition rules require a winning team after a drawn match (…), the \\nonly permitted procedures to determine the winning team are:\\n\\u2002•away goals rule\\n\\u2002•two equal periods of extra time not exceeding 15 minutes each\\n\\u2002•kicks from the penalty mark penalties (penalty shoot-out)\\nA combination of the above procedures may be used.', metadata={'page': 155, 'source': '/content/Laws of the Game 2023_24.pdf'}), Document(page_content='Practical \\nguidelines \\nfor match \\nofficials', metadata={'page': 175, 'source': '/content/Laws of the Game 2023_24.pdf'})]\n",
            ">>Bot:  External factors such as weather conditions can have a significant impact on the outcome of football matches. For example, heavy rain or fog can make it difficult for players to see the ball and control their movements, leading to mistakes and unpredictable outcomes. Thunderstorms or lightning can also pose a safety risk, requiring the match to be suspended until the conditions improve. Additionally, extreme heat or cold can affect player performance and stamina. Overall, weather conditions can influence the flow of the game, player abilities, and potentially result in a different outcome than if the conditions were more favorable.\n",
            ">>Bot: Source: /content/Laws of the Game 2023_24.pdf | Page: {'171', '177', '155', '175'}\n",
            ">>User::q\n",
            ">>Bot: Bye!\n"
          ]
        }
      ],
      "source": [
        "inference_w_decompose()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
